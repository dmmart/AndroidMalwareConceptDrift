import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import SGDClassifier
from sklearn.model_selection import train_test_split
from skmultiflow.drift_detection import ADWIN
from imblearn.over_sampling import SMOTE
from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score
from features import SYSTEMCALLS, PERMISSIONS
from visualization import Plot, Graph

FEATURES = SYSTEMCALLS + PERMISSIONS

class Scores:
    def __init__(self, name) -> None:
        self.name = name
        self.accuracy = []
        self.f1 = []
        self.precision = []
        self.recall = []
    
    def get_scores(self, accuracy, precision, recall, f1):
        self.accuracy.append(accuracy)
        self.f1.append(f1)
        self.precision.append(precision)
        self.recall.append(recall)
    
    def display(self):
        print(f'{self.name}_accuracy =', self.accuracy)
        print(f'{self.name}_f1 =', self.f1)
        print(f'{self.name}_recall =', self.recall)
        print(f'{self.name}_precision =', self.precision)

def train_model(data, balancer = None, classweight=None):
    X = data[FEATURES]
    y = data.Malware

    if balancer != None:
        X, y = balancer.fit_resample(X, y)
    
    if classweight == 'balanced':
        model = RandomForestClassifier(class_weight='balanced')
    else:
        model = RandomForestClassifier(n_jobs=-1)
    
    model.fit(X, y)

    return model

def train_sgd_model(data, balancer = None, classweight=None):
    X = data[FEATURES]
    y = data.Malware

    if balancer != None:
        X, y = balancer.fit_resample(X, y)
    
    if classweight == 'balanced':
        model = SGDClassifier(class_weight='balanced')
    else:
        model = SGDClassifier(n_jobs=-1)
    
    model.fit(X, y)

    return model


def evaluate(model, data, features):
    X_test = data[features]
    y_test = data.Malware

    y_pred = model.predict(X_test)

    accuracy = round(accuracy_score(y_test, y_pred) * 100, 1)
    precision = round(precision_score(y_test, y_pred) * 100, 1)
    recall = round(recall_score(y_test, y_pred) * 100, 1)
    f1 = round(f1_score(y_test, y_pred) * 100, 1)

    return accuracy, precision, recall, f1

def split_data(data, testsize):
    X = data[FEATURES]
    y = data.Malware

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testsize)

    X_train['Malware'] = y_train
    X_test['Malware'] = y_test

    return X_train, X_test

def main():
    sys_scores = Scores('sys_scores')
    per_scores = Scores('per_scores')
    both_scores = Scores('both_scores')

    data_train = pd.read_csv('./datasets/realistic_datasets/train/2010-Q1.csv')
    data_keep = pd.read_csv('./datasets/realistic_datasets/test/2010-Q1.csv')
    # data_train, data_keep = split_data(data, testsize=0.2)

    sys_model = RandomForestClassifier(n_jobs=-1)
    sys_model.fit(data_train[SYSTEMCALLS], data_train.Malware)

    per_model = RandomForestClassifier(n_jobs=-1)
    per_model.fit(data_train[PERMISSIONS], data_train.Malware)

    both_model = RandomForestClassifier(n_jobs=-1)
    both_model.fit(data_train[FEATURES], data_train.Malware)

    previous_samples = []
    previous_samples.append(data_keep)

    for year in range(2010, 2019, 1):
        for quater in [1, 2, 3, 4]:
            # file = f'./datasets/subsets_by_EarliestModDate/{year}-Q{quater}.csv'
            train_file = f'./datasets/realistic_datasets/train/{year}-Q{quater}.csv'
            test_file = f'./datasets/realistic_datasets/test/{year}-Q{quater}.csv'

            if train_file == './datasets/realistic_datasets/train/2010-Q1.csv' or test_file == './datasets/realistic_datasets/test/2010-Q1.csv':
                continue

            # new_data = pd.read_csv(file)

            # new_data_train, data_keep = split_data(new_data, testsize=0.2)

            new_data_train = pd.read_csv(train_file)
            data_test = pd.read_csv(test_file)

            # previous_dataframe = pd.concat(previous_samples).sample(frac=1)
            # data_test = pd.concat([new_data_train, previous_dataframe]).sample(frac=1)

            # previous_samples.append(data_keep)

            # evaluate
            accuracy, precision, recall, f1 = evaluate(sys_model, data_test, SYSTEMCALLS)
            sys_scores.get_scores(accuracy, precision, recall, f1)
            print(f'{year}-Q{quater}-M1 ', accuracy, precision, recall, f1)

            accuracy, precision, recall, f1 = evaluate(per_model, data_test, PERMISSIONS)
            per_scores.get_scores(accuracy, precision, recall, f1)
            print(f'{year}-Q{quater}-M2 ', accuracy, precision, recall, f1)

            accuracy, precision, recall, f1 = evaluate(both_model, data_test, FEATURES)
            both_scores.get_scores(accuracy, precision, recall, f1)
            print(f'{year}-Q{quater}-M3 ', accuracy, precision, recall, f1)

            # retrain

            data_train = pd.concat([data_train, new_data_train]).sample(frac=1)

            sys_model.fit(data_train[SYSTEMCALLS], data_train.Malware)
            per_model.fit(data_train[PERMISSIONS], data_train.Malware)
            both_model.fit(data_train[FEATURES], data_train.Malware)            
    
    sys_scores.display()
    per_scores.display()
    both_scores.display()

    # visualize
    accuracy_plot = Plot('Accuracy comparison of System calls, Permission and Both',
                         'accuracy_comparison_systemcalls_permissions_both_real_data.png')
    accuracy_plot.add_graph(Graph(sys_scores.accuracy, 'c', 'o', '-', 'System calls'))
    accuracy_plot.add_graph(Graph(per_scores.accuracy, 'y', 's', '-.', 'Permissions'))
    accuracy_plot.add_graph(Graph(both_scores.accuracy, 'm', 'v', ':', 'System calls + Permissions'))
    # accuracy_plot.add_graph(Graph(sgd_incremental_scores.accuracy, 'g', '*', '--', 'SGD incremental learning'))
    accuracy_plot.display()

    f1_plot = Plot('F1 comparison of System calls, Permission and Both',
                   'f1_comparison_systemcalls_permissions_both_real_data.png')
    f1_plot.add_graph(Graph(sys_scores.f1, 'c', 'o', '-', 'System calls'))
    f1_plot.add_graph(Graph(per_scores.f1, 'y', 's', '-.', 'Permissions'))
    f1_plot.add_graph(Graph(both_scores.f1, 'm', 'v', ':', 'System calls + Permissions'))
    f1_plot.display()

    recall_plot = Plot('Recall comparison of System calls, Permission and Both',
                       'recall_comparison_systemcalls_permissions_both_real_data.png')
    recall_plot.add_graph(Graph(sys_scores.recall, 'c', 'o', '-', 'System calls'))
    recall_plot.add_graph(Graph(per_scores.recall, 'y', 's', '-.', 'Permissions'))
    recall_plot.add_graph(Graph(both_scores.recall, 'm', 'v', ':', 'System calls + Permissions'))
    recall_plot.display()

    precision_plot = Plot('Precision comparison of System calls, Permission and Both',
                          'precision_comparison_systemcalls_permissions_both_real_data.png')
    precision_plot.add_graph(Graph(sys_scores.precision, 'c', 'o', '-', 'System calls'))
    precision_plot.add_graph(Graph(per_scores.precision, 'y', 's', '-.', 'Permissions'))
    precision_plot.add_graph(Graph(both_scores.precision, 'm', 'v', ':', 'System calls + Permissions'))
    precision_plot.display()

if __name__ == '__main__':
    main()