import pandas as pd
from sklearn.preprocessing import Normalizer, MinMaxScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import PassiveAggressiveClassifier
from sklearn.naive_bayes import BernoulliNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score
from features import SYSTEMCALLS, PERMISSIONS
from visualization import Plot, Graph

FEATURES = SYSTEMCALLS + PERMISSIONS

class Scores:
    def __init__(self, name) -> None:
        self.name = name
        self.accuracy = []
        self.f1 = []
        self.precision = []
        self.recall = []
    
    def get_scores(self, accuracy, precision, recall, f1):
        self.accuracy.append(accuracy)
        self.f1.append(f1)
        self.precision.append(precision)
        self.recall.append(recall)
    
    def display(self):
        print(f'{self.name}_accuracy =', self.accuracy)
        print(f'{self.name}_f1 =', self.f1)
        print(f'{self.name}_recall =', self.recall)
        print(f'{self.name}_precision =', self.precision)

def train_model(data, balancer = None, classweight=None):
    X = data[FEATURES]
    y = data.Malware

    if balancer != None:
        X, y = balancer.fit_resample(X, y)
    
    if classweight == 'balanced':
        model = RandomForestClassifier(class_weight='balanced')
    else:
        model = RandomForestClassifier(n_jobs=-1)
    
    model.fit(X, y)

    return model

def train_sgd_model(data, balancer = None, classweight=None):
    X = data[FEATURES]
    y = data.Malware

    if balancer != None:
        X, y = balancer.fit_resample(X, y)
    
    if classweight == 'balanced':
        model = PassiveAggressiveClassifier(class_weight='balanced')
    else:
        model = PassiveAggressiveClassifier(n_jobs=-1)
    
    model.fit(X, y)

    return model


def evaluate(model, data, features):
    X_test = data[features]
    y_test = data.Malware

    y_pred = model.predict(X_test)

    accuracy = round(accuracy_score(y_test, y_pred) * 100, 1)
    precision = round(precision_score(y_test, y_pred) * 100, 1)
    recall = round(recall_score(y_test, y_pred) * 100, 1)
    f1 = round(f1_score(y_test, y_pred) * 100, 1)

    return accuracy, precision, recall, f1

def split_data(data, testsize):
    X = data[FEATURES]
    y = data.Malware

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testsize)

    X_train['Malware'] = y_train
    X_test['Malware'] = y_test

    return X_train, X_test

def main():
    none_scores = Scores('none_scores')
    normalized_scores = Scores('normalized_scores')
    scaled_scores = Scores('scaled_scores')

    # data_train = pd.read_csv('./datasets/subsets_20_kept/train/2010-Q1.csv')
    # data_keep = pd.read_csv('./datasets/subsets_20_kept/test/2010-Q1.csv')
    # data_train, data_keep = split_data(data, testsize=0.2)

    data = pd.read_csv('./datasets/subsets_by_EarliestModDate/2010-Q1.csv')

    scaled_data = data.copy(deep=True)
    scaled_data[SYSTEMCALLS] = MinMaxScaler().fit_transform(scaled_data[SYSTEMCALLS])

    normalized_data = data.copy(deep=True)
    normalized_data[SYSTEMCALLS] = Normalizer().fit_transform(normalized_data[SYSTEMCALLS])

    print(normalized_data[SYSTEMCALLS].describe())

    none_model = RandomForestClassifier(n_jobs=-1)
    none_model.fit(data[FEATURES], data.Malware)

    scaled_model = RandomForestClassifier(n_jobs=-1)
    scaled_model.fit(scaled_data[FEATURES], scaled_data.Malware)

    normalized_model = RandomForestClassifier(n_jobs=-1)
    normalized_model.fit(normalized_data[FEATURES], normalized_data.Malware)

    # previous_samples = []
    # previous_samples.append(data_keep)

    for year in range(2010, 2019, 1):
        for quater in [1, 2, 3, 4]:
            file = f'./datasets/subsets_by_EarliestModDate/{year}-Q{quater}.csv'
            # train_file = f'./datasets/subsets_20_kept/train/{year}-Q{quater}.csv'
            # test_file = f'./datasets/subsets_20_kept/test/{year}-Q{quater}.csv'

            # if train_file == './datasets/subsets_20_kept/train/2010-Q1.csv' or test_file == './datasets/subsets_20_kept/test/2010-Q1.csv':
            #     continue

            if file == './datasets/subsets_by_EarliestModDate/2010-Q1.csv':
                continue

            new_data = pd.read_csv(file)

            normalized_new_data = new_data.copy(deep=True)
            normalized_new_data[SYSTEMCALLS] = Normalizer().fit_transform(normalized_new_data[SYSTEMCALLS])

            scaled_new_data = new_data.copy(deep=True)
            scaled_new_data[SYSTEMCALLS] = MinMaxScaler().fit_transform(scaled_new_data[SYSTEMCALLS])

            # new_data_train, data_keep = split_data(new_data, testsize=0.2)

            # new_data_train = pd.read_csv(train_file)
            # data_test = pd.read_csv(test_file)

            # previous_dataframe = pd.concat(previous_samples).sample(frac=1)
            # data_test = pd.concat([new_data_train, previous_dataframe]).sample(frac=1)

            # previous_samples.append(data_keep)

            # evaluate
            accuracy, precision, recall, f1 = evaluate(none_model, new_data, FEATURES)
            none_scores.get_scores(accuracy, precision, recall, f1)
            print(f'{year}-Q{quater}-M1 ', accuracy, precision, recall, f1)

            accuracy, precision, recall, f1 = evaluate(normalized_model, new_data, FEATURES)
            normalized_scores.get_scores(accuracy, precision, recall, f1)
            print(f'{year}-Q{quater}-M2 ', accuracy, precision, recall, f1)

            accuracy, precision, recall, f1 = evaluate(scaled_model, new_data, FEATURES)
            scaled_scores.get_scores(accuracy, precision, recall, f1)
            print(f'{year}-Q{quater}-M3 ', accuracy, precision, recall, f1)

            # update model

            data = pd.concat([data, new_data]).sample(frac=1)
            normalized_data = pd.concat([normalized_data, normalized_new_data]).sample(frac=1)
            scaled_data = pd.concat([scaled_data, scaled_new_data]).sample(frac=1)

            none_model.fit(data[FEATURES], data.Malware)
            normalized_model.fit(normalized_data[FEATURES], normalized_data.Malware)
            scaled_model.fit(scaled_data[FEATURES], scaled_data.Malware)
    
    none_scores.display()
    normalized_scores.display()
    scaled_scores.display()

    # visualize
    accuracy_plot = Plot('Accuracy comparison of different normalization strategies',
                         'accuracy_comparison_Normalization_On_RandomForestClassifier_new_data.png')
    accuracy_plot.add_graph(Graph(none_scores.accuracy, 'y', 's', '-.', 'not normalized'))
    accuracy_plot.add_graph(Graph(normalized_scores.accuracy, 'c', 'o', '-', 'Normalizer()'))
    accuracy_plot.add_graph(Graph(scaled_scores.accuracy, 'm', 'v', ':', 'MinMaxScaler()'))
    # accuracy_plot.add_graph(Graph(retrain_scores.accuracy, 'g', '*', '--', 'retrain'))  
    accuracy_plot.display()

    f1_plot = Plot('F1 comparison of different normalization strategies',
                   'f1_comparison_Normalization_On_RandomForestClassifier_new_data.png')
    f1_plot.add_graph(Graph(none_scores.f1, 'y', 's', '-.', 'not normalized'))
    f1_plot.add_graph(Graph(normalized_scores.f1, 'c', 'o', '-', 'Normalizer()'))
    f1_plot.add_graph(Graph(scaled_scores.f1, 'm', 'v', ':', 'MinMaxScaler()'))
    f1_plot.display()

    recall_plot = Plot('Recall comparison of different normalization strategies',
                       'recall_comparison_Normalization_On_RandomForestClassifier_new_data.png')
    recall_plot.add_graph(Graph(none_scores.recall, 'y', 's', '-.', 'not normalized'))
    recall_plot.add_graph(Graph(normalized_scores.recall, 'c', 'o', '-', 'Normalizer()'))
    recall_plot.add_graph(Graph(scaled_scores.recall, 'm', 'v', ':', 'MinMaxScaler()')) 
    recall_plot.display()

    precision_plot = Plot('Precision comparison of different normalization strategies',
                          'precision_comparison_Normalization_On_RandomForestClassifier_new_data.png')
    precision_plot.add_graph(Graph(none_scores.precision, 'y', 's', '-.', 'not normalized'))
    precision_plot.add_graph(Graph(normalized_scores.precision, 'c', 'o', '-', 'Normalizer()'))
    precision_plot.add_graph(Graph(scaled_scores.precision, 'm', 'v', ':', 'MinMaxScaler()'))
    precision_plot.display()

if __name__ == '__main__':
    main()